* Methods to avoid Over-fitting:
* Cross-Validation : 
  * Cross Validation in its simplest form is a one round validation,
  * where we leave one sample as in-time validation and rest for training the model. 
  * But for keeping lower variance a higher fold cross validation is preferred.
* Early Stopping : 
  * Early stopping rules provide guidance as to 
    how many iterations can be run before the learner begins to over-fit.
* Pruning :
  * Pruning is used extensively while building CART models. 
  * It simply removes the nodes which add little predictive power for the problem in hand.
* Regularization : 
  * it introduces a cost term for bringing in more features with the objective function.
  * Hence, it tries to push the coefficients for many variables to zero and hence reduce cost term.
