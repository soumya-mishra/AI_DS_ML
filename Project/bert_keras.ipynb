{
  
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "bert-keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5123ece8081e47d393e9f65beff92184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d3d4f1c4b85744f6901c10395e6b8245",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41cfec8bc2324981a9eb592f57483ca1",
              "IPY_MODEL_bfe18cf542464b6486d519764dfac8e4"
            ]
          }
        },
        "d3d4f1c4b85744f6901c10395e6b8245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41cfec8bc2324981a9eb592f57483ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f7f844f054bf40e987fb66c65895d4f1",
            "_dom_classes": [],
            "description": "Converting examples to features",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 62469,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62469,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f8c174600764113b5fa2c4e2ebb3072"
          }
        },
        "bfe18cf542464b6486d519764dfac8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29338ef5b7a447c8a6830088c733e2de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 62469/62469 [01:12&lt;00:00, 862.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a332203742d2418891d365eb44916ae0"
          }
        },
        "f7f844f054bf40e987fb66c65895d4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f8c174600764113b5fa2c4e2ebb3072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29338ef5b7a447c8a6830088c733e2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a332203742d2418891d365eb44916ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31ec2b79cdc94d99a264902e70412f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ef73be738d984ccdac78dcc6d29a0aad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b84a69ce71c4906908387aecfbdb09d",
              "IPY_MODEL_7d9c129c93e0497f9d3fedfc4b4d4845"
            ]
          }
        },
        "ef73be738d984ccdac78dcc6d29a0aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b84a69ce71c4906908387aecfbdb09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4579f58f9d6b44ad9071ea9b2b820363",
            "_dom_classes": [],
            "description": "Converting examples to features",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 6941,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6941,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01a253ddfe1b4482b13e760ce4c107bd"
          }
        },
        "7d9c129c93e0497f9d3fedfc4b4d4845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_26d9e73c9fec48ea8a18efff601fee62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 6941/6941 [00:08&lt;00:00, 861.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ed7823f320f4148be33426a19f10f07"
          }
        },
        "4579f58f9d6b44ad9071ea9b2b820363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01a253ddfe1b4482b13e760ce4c107bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26d9e73c9fec48ea8a18efff601fee62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ed7823f320f4148be33426a19f10f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumya-mishra/Python-ML/blob/master/Project/bert_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1DgnVid77ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n",
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n",
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/tokenization.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5nJRucc77em",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "6e2157e8-9642-4a4a-8cd2-7d16e52ab4c3"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import sys\n",
        "import zipfile\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import tokenization\n",
        "\n",
        "from tokenization import FullTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_7YkZ_s77er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "# Params for bert model and tokenization\n",
        "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "max_seq_length = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta5lwcr19FQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "683e03e6-9f7d-410e-d1a5-77e45089b0bb"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "350eWgtN77ex",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO3yVf6l77ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/content/train.csv', index_col='id')\n",
        "val_df = pd.read_csv('/content/valid.csv', index_col='id')\n",
        "test_df = pd.read_csv('/content/test.csv', index_col='id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xqMrRwJ77e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = LabelEncoder().fit(pd.concat([train_df['label'], val_df['label']]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86971VRu77e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_val, X_test = pd.concat([train_df['text'], val_df['text']]).values, test_df['text'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucw2bEFJ77fB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_val = label_encoder.fit_transform(pd.concat([train_df['label'], val_df['label']]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2oJm8kZ77fE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val,y_train_val, test_size=0.1, random_state=0, stratify = y_train_val\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibt0yCxs77fG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = X_train\n",
        "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\n",
        "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
        "train_label = y_train\n",
        "\n",
        "val_text = X_val\n",
        "val_text = [' '.join(t.split()[0:max_seq_length]) for t in val_text]\n",
        "val_text = np.array(val_text, dtype=object)[:, np.newaxis]\n",
        "val_label = y_val\n",
        "\n",
        "test_text = X_test\n",
        "test_text = [' '.join(t.split()[0:max_seq_length]) for t in test_text]\n",
        "test_text = np.array(test_text, dtype=object)[:, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMfseZz77fK",
        "colab_type": "text"
      },
      "source": [
        "# Bert tf-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nFDvJHG77fL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80215915-f568-4960-8aeb-564ddd7e5ee7"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "#from tensorflow.keras import backend as K\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "\n",
        "\n",
        "class BertLayer(Layer):\n",
        "    \n",
        "    '''BertLayer which support next output_representation param:\n",
        "    \n",
        "    pooled_output: the first CLS token after adding projection layer () with shape [batch_size, 768]. \n",
        "    sequence_output: all tokens output with shape [batch_size, max_length, 768].\n",
        "    mean_pooling: mean pooling of all tokens output [batch_size, max_length, 768].\n",
        "    \n",
        "    \n",
        "    You can simple fine-tune last n layers in BERT with n_fine_tune_layers parameter. For view trainable parameters call model.trainable_weights after creating model.\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    def __init__(self, n_fine_tune_layers=10, tf_hub = None, output_representation = 'pooled_output', trainable = False, **kwargs):\n",
        "        \n",
        "        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "        self.is_trainble = trainable\n",
        "        self.output_size = 768\n",
        "        self.tf_hub = tf_hub\n",
        "        self.output_representation = output_representation\n",
        "        self.supports_masking = True\n",
        "        \n",
        "        super(BertLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.bert = hub.Module(\n",
        "            self.tf_hub,\n",
        "            trainable=self.is_trainble,\n",
        "            name=\"{}_module\".format(self.name)\n",
        "        )\n",
        "        \n",
        "        \n",
        "        variables = list(self.bert.variable_map.values())\n",
        "        if self.is_trainble:\n",
        "            # 1 first remove unused layers\n",
        "            trainable_vars = [var for var in variables if not \"/cls/\" in var.name]\n",
        "            \n",
        "            \n",
        "            if self.output_representation == \"sequence_output\" or self.output_representation == \"mean_pooling\":\n",
        "                # 1 first remove unused pooled layers\n",
        "                trainable_vars = [var for var in trainable_vars if not \"/pooler/\" in var.name]\n",
        "                \n",
        "            # Select how many layers to fine tune\n",
        "            trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
        "            \n",
        "            # Add to trainable weights\n",
        "            for var in trainable_vars:\n",
        "                self._trainable_weights.append(var)\n",
        "\n",
        "            # Add non-trainable weights\n",
        "            for var in self.bert.variables:\n",
        "                if var not in self._trainable_weights:\n",
        "                    self._non_trainable_weights.append(var)\n",
        "                \n",
        "        else:\n",
        "             for var in variables:\n",
        "                self._non_trainable_weights.append(var)\n",
        "                \n",
        "\n",
        "        super(BertLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
        "        input_ids, input_mask, segment_ids = inputs\n",
        "        bert_inputs = dict(\n",
        "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
        "        )\n",
        "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
        "        \n",
        "        if self.output_representation == \"pooled_output\":\n",
        "            pooled = result[\"pooled_output\"]\n",
        "            \n",
        "        elif self.output_representation == \"mean_pooling\":\n",
        "            result_tmp = result[\"sequence_output\"]\n",
        "        \n",
        "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
        "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
        "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
        "            input_mask = tf.cast(input_mask, tf.float32)\n",
        "            pooled = masked_reduce_mean(result_tmp, input_mask)\n",
        "            \n",
        "        elif self.output_representation == \"sequence_output\":\n",
        "            \n",
        "            pooled = result[\"sequence_output\"]\n",
        "       \n",
        "        return pooled\n",
        "    \n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        \n",
        "        if self.output_representation == 'sequence_output':\n",
        "            inputs = [K.cast(x, dtype=\"bool\") for x in inputs]\n",
        "            mask = inputs[1]\n",
        "            \n",
        "            return mask\n",
        "        else:\n",
        "            return None\n",
        "        \n",
        "        \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.output_representation == \"sequence_output\":\n",
        "            return (input_shape[0][0], input_shape[0][1], self.output_size)\n",
        "        else:\n",
        "            return (input_shape[0][0], self.output_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lS1hvet77fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKJACbnj77fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(max_seq_length, tf_hub, n_classes, n_fine_tune): \n",
        "    in_id = keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
        "    in_mask = keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
        "    in_segment = keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    \n",
        "    bert_output = BertLayer(n_fine_tune_layers=n_fine_tune, tf_hub = tf_hub, output_representation = 'mean_pooling', trainable = True)(bert_inputs)\n",
        "    drop = keras.layers.Dropout(0.3)(bert_output)\n",
        "    dense = keras.layers.Dense(256, activation='sigmoid')(drop)\n",
        "    drop = keras.layers.Dropout(0.3)(dense)\n",
        "    dense = keras.layers.Dense(64, activation='sigmoid')(drop)\n",
        "    pred = keras.layers.Dense(n_classes, activation='softmax')(dense)\n",
        "    \n",
        "    model = keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "    Adam = keras.optimizers.Adam(lr = 0.0005)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam, metrics=['sparse_categorical_accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def initialize_vars(sess):\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LekS81CW77fb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jrG3Qsc77fc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "e203babf-08ba-43bc-9065-0095bac714fe"
      },
      "source": [
        "\n",
        "n_classes = len(label_encoder.classes_)\n",
        "n_fine_tune_layers = 48\n",
        "model = build_model(max_seq_length, bert_path, n_classes, n_fine_tune_layers)\n",
        "\n",
        "# Instantiate variables\n",
        "initialize_vars(sess)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_layer_1 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 768)          0           bert_layer_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          196864      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           16448       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 6)            390         dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 110,318,592\n",
            "Trainable params: 21,477,318\n",
            "Non-trainable params: 88,841,274\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AZ6moeb77fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "3498c8aa-e366-4154-e8cf-357bcccd9e1e"
      },
      "source": [
        "model.trainable_weights"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'bert_layer_1_module/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
              " <tf.Variable 'dense_1/kernel:0' shape=(768, 256) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(256,) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_2/kernel:0' shape=(256, 64) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_3/kernel:0' shape=(64, 6) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_3/bias:0' shape=(6,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgh5IHnp77fk",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLRFc_Sc77fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PaddingInputExample(object):\n",
        "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
        "  When running eval/predict on the TPU, we need to pad the number of examples\n",
        "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
        "  size. The alternative is to drop the last batch, which is bad because it means\n",
        "  the entire output data won't be generated.\n",
        "  We use this class instead of `None` because treating `None` as padding\n",
        "  battches could cause silent errors.\n",
        "  \"\"\"\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "    Args:\n",
        "      guid: Unique id for the example.\n",
        "      text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "        Only must be specified for sequence pair tasks.\n",
        "      label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "def create_tokenizer_from_hub_module(tf_hub):\n",
        "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "    bert_module =  hub.Module(tf_hub)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    vocab_file, do_lower_case = sess.run(\n",
        "        [\n",
        "            tokenization_info[\"vocab_file\"],\n",
        "            tokenization_info[\"do_lower_case\"],\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        input_ids = [0] * max_seq_length\n",
        "        input_mask = [0] * max_seq_length\n",
        "        segment_ids = [0] * max_seq_length\n",
        "        label = 0\n",
        "        return input_ids, input_mask, segment_ids, label\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "    \n",
        "    #print(tokens)\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    return input_ids, input_mask, segment_ids, example.label\n",
        "\n",
        "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
        "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
        "        input_id, input_mask, segment_id, label = convert_single_example(\n",
        "            tokenizer, example, max_seq_length\n",
        "        )\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels).reshape(-1, 1),\n",
        "    )\n",
        "\n",
        "def convert_text_to_examples(texts, labels):\n",
        "    \"\"\"Create InputExamples\"\"\"\n",
        "    InputExamples = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        InputExamples.append(\n",
        "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
        "        )\n",
        "    return InputExamples\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK91xJiI77fn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219,
          "referenced_widgets": [
            "5123ece8081e47d393e9f65beff92184",
            "d3d4f1c4b85744f6901c10395e6b8245",
            "41cfec8bc2324981a9eb592f57483ca1",
            "bfe18cf542464b6486d519764dfac8e4",
            "f7f844f054bf40e987fb66c65895d4f1",
            "7f8c174600764113b5fa2c4e2ebb3072",
            "29338ef5b7a447c8a6830088c733e2de",
            "a332203742d2418891d365eb44916ae0",
            "31ec2b79cdc94d99a264902e70412f64",
            "ef73be738d984ccdac78dcc6d29a0aad",
            "6b84a69ce71c4906908387aecfbdb09d",
            "7d9c129c93e0497f9d3fedfc4b4d4845",
            "4579f58f9d6b44ad9071ea9b2b820363",
            "01a253ddfe1b4482b13e760ce4c107bd",
            "26d9e73c9fec48ea8a18efff601fee62",
            "0ed7823f320f4148be33426a19f10f07"
          ]
        },
        "outputId": "c1590e9b-c271-42cf-b138-4d161824d9f5"
      },
      "source": [
        "# Instantiate tokenizer\n",
        "tokenizer = create_tokenizer_from_hub_module(bert_path)\n",
        "\n",
        "# Convert data to InputExample format\n",
        "train_examples = convert_text_to_examples(train_text, train_label)\n",
        "val_examples = convert_text_to_examples(val_text, val_label)\n",
        "\n",
        "# Convert to features\n",
        "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
        ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
        "(val_input_ids, val_input_masks, val_segment_ids, val_labels\n",
        ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=max_seq_length)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5123ece8081e47d393e9f65beff92184",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=62469, style=ProgressStâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31ec2b79cdc94d99a264902e70412f64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=6941, style=ProgressStyâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d-3A05277fr",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D02tDcOr77fs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "43c3dad4-fb9e-456d-e696-ac4a145cbc23"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "MONITOR = 'val_sparse_categorical_accuracy'\n",
        "print('BATCH_SIZE is {}'.format(BATCH_SIZE))\n",
        "e_stopping = EarlyStopping(monitor=MONITOR, patience=3, verbose=1, mode='max', restore_best_weights=True)\n",
        "callbacks =  [e_stopping]\n",
        "\n",
        "history = model.fit(\n",
        "   [train_input_ids, train_input_masks, train_segment_ids], \n",
        "    train_labels,\n",
        "    validation_data = ([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
        "    epochs = 10,\n",
        "    verbose = 1,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    callbacks= callbacks\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATCH_SIZE is 256\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 62469 samples, validate on 6941 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 1024/62469 [..............................] - ETA: 7:43:06 - loss: 1.7131 - sparse_categorical_accuracy: 0.2881"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmyWb4iG77fu",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yjKyWY677fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_examples = convert_text_to_examples(test_text, np.zeros(len(test_text)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KsCy0br77fy",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "fc7f4a34bbe3494687f51f19625d2b1e"
          ]
        },
        "outputId": "fce99b8c-403a-401f-f346-b99b6936b082"
      },
      "source": [
        "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
        ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc7f4a34bbe3494687f51f19625d2b1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=17353, style=ProgressStâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLUKlOO-77f2",
        "colab_type": "code",
        "colab": {},
        "outputId": "bbed224e-3ade-4792-ade7-e44cffd1f5b1"
      },
      "source": [
        "prediction = model.predict([test_input_ids, test_input_masks, test_segment_ids], verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17353/17353 [==============================] - 83s 5ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFnL7bDl77f6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = label_encoder.classes_[np.argmax(prediction, axis =1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0-_sETj77f8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(preds, columns=['label']).to_csv('bert_keras_submission.csv',\n",
        "                                                  index_label='id')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
