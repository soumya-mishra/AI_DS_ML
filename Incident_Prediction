#GradientTreeBoosting

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


# Importing the dataset
dataset = pd.read_excel(r'C:\Users\I324158\Desktop\incidentdata.xlsx')
X = dataset.iloc[:, 0:1].values
y = dataset.iloc[:, 1].values
#
#plt.plot(X,y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1 )

# Regression to the dataset
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.ensemble import GradientBoostingRegressor
params = {'n_estimators': 107, 'max_depth': 6,
        'learning_rate': 0.01, 'min_samples_split':12,'max_leaf_nodes':12,'subsample':0.4}

regressor = GradientBoostingRegressor(**params)
regressor.fit(X_train,y_train)
y_pred = regressor.predict(X_test)

mse = mean_squared_error(y_test, regressor.predict(X_test))

r2 = r2_score(y_test, regressor.predict(X_test))

print("MSE: %.4f" % mse)
print("R2: %.4f" % r2)

regressor.score(X_train, y_train)

regressor.score(X_test, y_test)

# Plot training deviance

# compute test set deviance
test_score = np.zeros((params['n_estimators'],), dtype=np.float64)

for i, y_pred in enumerate(regressor.staged_predict(X_test)):
    test_score[i] = regressor.loss_(y_test, y_pred)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Deviance')
plt.plot(np.arange(params['n_estimators']) + 1, regressor.train_score_, 'b-',
         label='Training Set Deviance')
plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',
         label='Test Set Deviance')
plt.legend(loc='upper right')
plt.xlabel('Boosting Iterations')
plt.ylabel('Deviance')



